%
% FILE:     standards (Master)
%
% LOCATION: /neuro/cartman/user/saam/nase/doc/standards/
%
% AUTHOR:   saam
%
% DATE:     Thu Aug 24 10:29:40 CEST 2000
%
% MODIFICATION HISTORY:
%
%       $Log$
%       Revision 1.11  2000/10/03 17:29:14  saam
%       *included suggestions and decision from workshop
%       *categories still under construction
%
%       Revision 1.10  2000/09/29 14:03:33  brinks
%       completed chapter for performance improvements and traps
%
%       Revision 1.9  2000/09/28 07:59:56  saam
%       changes to documentation header subsection
%
%       Revision 1.8  2000/09/26 14:05:27  saam
%       changes to directory structure
%
%       Revision 1.7  2000/09/25 14:13:59  saam
%       updated the doc header
%       appendend short description of console
%
%       Revision 1.6  2000/09/22 18:32:03  saam
%             added some todos
%
%       Revision 1.5  2000/09/21 10:09:17  saam
%             updated doc section
%
%       Revision 1.4  2000/09/09 16:09:47  saam
%            dunno whats changed
%
%       Revision 1.3  2000/08/25 10:09:22  saam
%            compatability added
%
%       Revision 1.2  2000/08/24 16:46:12  saam
%             extended the messaging section
%
%       Revision 1.1  2000/08/24 10:01:32  saam
%             first version
%
%
%-
\documentclass[12pt]{article}


% Page Size & Formatting
\usepackage[a4paper,dvips]{geometry}           % page layout [twoside]
\setlength{\parindent}{0pt}                    % dont indent first paragraph
%\renewcommand{\baselinestretch}{2.0}          % double line spacing
%\usepackage{showlabels}                       % shows labels on side margin
\usepackage{showkeys}                          % prints label, ref, cite and bib keys
\usepackage{draftcopy}                         % displays draft in background of page (ps only!)
\usepackage{changebar}                         % changebars at margin via \cbstart ... \cbend (ps only!)
\usepackage{verbatim}

% References & Citations
\usepackage{lastpage}                          % access last page by \pageref{LastPage}
\usepackage[round]{natbib}                     % citestyle: Author (Year) by \cite or Author, Year with \citet
\usepackage{prettyref}                         % generates references like Figure/Table/Equation x, instead of x 
\newrefformat{fig}{Figure~\ref{#1}}
\usepackage{acronym}                           % make sure acronyms are spelled out at least once

% Language
\usepackage[english]{babel}                    % set the language (german, english, ...)
\usepackage[latin1]{inputenc}                  % allow special characters directly in source

% Headers & Footers
\usepackage{fancyheadings}                     % allows individual header and footers
\pagestyle{fancy}
\lhead{\tiny \$Header$ $\$}                    % include path/name/date/RCS/CVS-version in header
\chead{}
\rhead{}
%\lfoot{}
%\cfoot{}
%\rfoot{}


% Fonts
%\usepackage{times}                            % use times, palatino, ...  ps-fonts instead of cm (dvi won't work!!)
%\usepackage{soul}                             % typeset text in spaced out way via \st{...} and more
\usepackage{SIunits}                           % use SI units by their name and produce upright greek symbols

        
% Figures & Captions
\usepackage{graphicx}
\usepackage[footnotesize,nooneline]{caption}
\DeclareGraphicsRule{.tif}{eps}{.bb}{`convert #1 eps:-}
\DeclareGraphicsRule{.gif}{eps}{.bb}{`convert #1 eps:-}
\DeclareGraphicsRule{.bmp}{eps}{.bb}{`convert #1 eps:-}
\DeclareGraphicsRule{.jpg}{eps}{.bb}{`convert #1 eps:-}
% TeX requirements for putting a figure onto a page
% are rather strict (and therefore seldom fulfilled
% the following command make the placement of figures
% more sloppier
\renewcommand{\textfraction}{0.1}
\renewcommand{\topfraction}{0.9}
\renewcommand{\bottomfraction}{0.9}


% Definitions
% the way a bind figures into the document:
\newcommand{\myfig}[5]{\begin{figure}[tbh]\begin{center}\includegraphics[#3]{#2}\caption{\label{#1}{\sc#4.} #5}\end{center}\end{figure}}


% define an acronym by: 
%   \acrodef{CCH}{cross coincidence histogram} 
% following commands produce the shown output:
%   \ac{CCH}  -> cross coincidence histogram (CCH)  % for the first appearance 
%   \ac{CCH}  -> CCH                                % any further appearance
%   \acf{CCH} -> cross coincidence histogram (CCH)  % always
%   \acl{CCH} -> cross coincidence histogram        % always
%   \acs{CCH} -> CCH                                % always
% you can also make a list of acronyms (see documentation)


% integrate figures by:
%   \myfig{label}{filename}{width,height}{short-title}{description}


\begin{document}
\begin{titlepage}
\begin{center}
{\Huge\textbf{N.A.S.E. / M.I.N.D. Standards}\\[2cm]}
Version: \$Id$ $\$ 
\end{center}
\vfill
\tableofcontents
\vfill
\vfill
\end{titlepage}

%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\section{Documentation}
%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%
\subsection{General}
\begin{itemize}
\item The only accepted documentation language is English. There are lots of old routines documented in German. This has to be changed! If such a routine is modified, it has to be translated. 
\item Documentation is not only for others, it is for you as well. Remember lots of routines you wrote to finish that paper last summer, and now you can only guess what they are doing. And you will probably code them completely new to get them working with a new set of data. Or you forgot, that they exist. This does not only count for the usage, but also for the implementation of your code. So once again: \textbf{Document everything, for you and others.}
\end{itemize}

\subsection{Documentation Header}
A current version of the documentation header can always be found in the doc directory of nase call \texttt{header.pro}.

\verbatiminput{../header.pro}

\begin{itemize}
\item The use of other identifiers as specified above is strictly prohibited.
\item Identifiers mentioned above are needed to syntactically parse the header. Don't use them in your descriptions (e.g., \texttt{See also:}), because this
      confuses scanning and leads to terrible results. Should we restrict tag names to all upper-case, to reduce probability for conflicts?
\item Should we check to correct parsing during commit? Shouldn't add a global modification history to the web pages?
\end{itemize}

\subsection{CVS Logs}
\begin{itemize}
\item Please produce a log message, that other people are able to understand what you have changed. Expressions like \texttt{small bug fix} are not accaptable (what was the bug? how was it fixed?).  
\end{itemize}




%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\section{Routines}
%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%
\subsection{Naming}
\begin{itemize}
\item Names of routines must not contain any special character like language specific extension, underscores. To keep problems between different operation systems small, just use lower case letters \texttt{a-z}. Names are not restricted in length, but the shorter a name, the better it is to type.  
\item Routine names are expected to describe, what they are supposed to do. Names like \texttt{eval.pro} are not acceptable.
\item Check that the name you like to chose is free for use.
\item If there is a bundle of routines (perhaps handling a special data structure), compound words in increasing specifity should be used. E.g., if you have routines handling a list, they can be called like \texttt{listinsert}, \texttt{listsort}.
\end{itemize}


\subsection{Compatibility between IDL versions}
Different types of compatilibity problems are known between IDL versions. First (the harmless one), higher version include routines, which formerly had to be implemented by hand. Furthermore, already existing routines are extended in their functionality, making several hand-written wrappers obsolete. Last, but most problematic are undocumented (silent) changes in the behaviour of routines, i.e. color management, handling of the \texttt{\_EXTRA} keyword, passing of undefined arguments. The following guidelines are a compromise between functionality and compatability:
\begin{itemize}
\item If a new IDL routines makes a NASE routine obsolete, disable the NASE routine, generate a message about the fact, remove the routine after 2 months from the repository.
\item For changes in IDL's behaviour: all routines must work with (and only with) the current IDL version. The only exception is the NASE/MIND simulation kernel.
\end{itemize}

\subsection{Error Handling and Messaging}
\begin{itemize}
%
\item Wrong number, type, dimensions of positional or keyword parameters should stop the routine at the position of the calling program segment. For this you should place 
\begin{verbatim}
On_Error, 2
\end{verbatim}
(after testing and debugging, of course) at the very beginning of your routine. To produce the actual error message, use
\begin{verbatim}
Console, 'error message', /FATAL .
\end{verbatim}
%
\item All nonfatal errors, strange conditions or status messages during the processing of the routine, should be logged via
\begin{verbatim}
Console, 'what happened' [,/MSG | ,/INFO] 
\end{verbatim}
With this policy the user can decide if he/she actually wants to see all this stuff by changing the console properties.
%
\item Fatal errors should stop the routine at the position of the calling program segment. You may implement a fallback, that the calling function may use to handle the error. This should look like:
\begin{verbatim}
PRO RoutineGeneratingError, ERROR=error
On_Error, 2
...
; a fatal error has occured
IF Keyword_Set(ERROR) THEN BEGIN
                             error=1 ; or another documented value/string
                             RETURN
                           END ELSE Console, 'fatal error', /FATAL
...
END
\end{verbatim}
%
\item The console provides a unified message-mechanism for all
  NASE/MIND routines. The commonly used methods like \texttt{print} and
  \texttt{message} have the disadvantage, that you can't supress these
  logs. Console provides messaging using different importance levels
  (e.g., message, warning, fatal) and the user can decide what level
  to ignore, which to log and when the execution has to be stopped.
\end{itemize}
\subsection{Syntax Checking}
\begin{itemize}
\item The syntax and semantics of the passed arguments should be checked as strict/extensive as possible. If the routine is time critical (called many times), the checking can be skipped by the keyword \texttt{/FAST}. You also may omit the syntax check, if documented in the \texttt{Restrictions} section. 
\end{itemize}
\subsection{Calling Conventions}
\begin{itemize}
\item The time should be the first index in all array operations.
\end{itemize}


%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%
\section{Efficient Programming}
%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%

There are some rules one should take into account to improve a program's perormance. In addition to well known tricks that work with every language there are many particular for IDL. In the following you find  some 'Dos and Don'ts' to speed up programs with low needs of memory. The two sections \textit{Improving Speed} and \textit{Reducing Memory Consumption} present a set of the most important rules, while the third section \textit{How long does it really take?} compares different implementations in benchmarks.


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Improving Speed}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{itemize}

\item IDL supplies a number of built-in functions and procedures to perform common operations. These system-supplied functions have been optimized and are faster than writing the equivalent operations in IDL, particularly if loops and \texttt{if} statements are used. This leads to the 'golden rule': \textbf{Use array operations rather than loops or \texttt{if} statements.}

\item If you have to use loops, try to eliminate invariant expressions inside the loop. For example, in the loop
\begin{verbatim}
FOR I = 0, N - 1 DO arr[I, 2*J-1] = ...,
\end{verbatim}
the expression (2*J-1) is invariant and should be evaluated only once before the loop is entered:
\begin{verbatim}
temp = 2*J-1
FOR I = 0, N-1 DO arr[I, temp] = ....
\end{verbatim}

\item Avoid type conversion, if it is not necessary. Consider the following expression:
\begin{verbatim}
A + 5
\end{verbatim}
If the variable \texttt{A} is of floating-point type, the constant \texttt{5} must be converted from short integer type to floating point each time the expression is evaluated. 

\item Use the first index in an array for successional data (normally the time or frequency domain). Due to the internal representation of arrays in memory, operations in this first dimension are faster, at least in the majority of cases.

\item Try to access large (square)-arrays by memory order. 

\item Use the \texttt{NOZERO} keyword when declaring arrays, that needn't be initialized with zeros

\item Use the \texttt{REPLICATE\_INPLACE} procedure to update existing arrays by replacing all or selected parts of it with a specified value. 

\item Use \texttt{REBIN} instead of \texttt{CONGRID} if possible.

\item Use \texttt{ROTATION} instead of \texttt{ROT} when rotating an array or image by 90° or multiples. 

\item Use \texttt{CALL\_FUNCTION} or \texttt{CALL\_PROCEDURE} instead of \texttt{EXECUTE}.

\item Use the \texttt{FFT} function with a number of data that is equal to a power of two.

\item Use a clever order of expressions. For example
\begin{verbatim}
B=A*16./MAX(A)
\end{verbatim}
is slower than
\begin{verbatim}
B=16./MAX(A)*A
\end{verbatim}



\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Reducing Memory Consumption}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{itemize}

\item Do not waste memory, but try to tailor your program to a minimal use of it. Keep in mind that IDL needs to create temporary arrays when evaluating expressions. This often multiplies the memory requirements!

\item Delete a variable's allocation that appears on the left site of an expression. Consider the following:
\begin{verbatim}
A=fltarr(512,512)
A=image_expression
...
A=(B+C)*(E+F) ,   A,B,E arrays, C,F arrays or something else.
\end{verbatim}
A contains some data, e.g. an image, but now these values shall be replaced by \texttt{(B+D)*(E+F)}. When entering the last line, there is a huge amount of memory allocated for all five variables A to F. While evaluation, IDL allocates for each sub-expression \texttt{(B+C)} and \texttt{(E+F)} temporary memory, in this case two arrays (512,512), in addition. Then the right side of the expression is computed and stored in a temporary area. Remember, the old data content of A is still in memory. Finally this allocation of \texttt{A} is deleted and replaced by the new result and the temporary allocations are freed.
To save memory it is a clever idea, to free \texttt{A's} memory before entering the last line:
\begin{verbatim}
A=fltarr(512,512)
A=image_expression
...
A=0b
A=(B+C)*(E+F) ,   A,B,E arrays, C,F arrays or something else.
\end{verbatim}
Setting \texttt{A} to a byte just takes one byte of memory.

\item Use the \texttt{TEMPORARY} function to minimize memory use. Example:
\begin{verbatim}
A=A+1
\end{verbatim}
To evaluate this, IDL allocates memory for the right side of the expression and calculates \texttt{A+1}. The old value of \texttt{A} is still in memory, until the new results is assigned to \texttt{A} and the old stuff deleted. This uses twice the size of \texttt{A} in memory. On the other hand
\begin{verbatim}
A=TEMPORARY(A)+1
\end{verbatim}
uses once the size of \texttt{A}. \texttt{TEMPORARY} frees the allocated area of it's argument, in this case \texttt{A}. Then IDL calculates the right side of the expression, with a memory use of just the size of \texttt{A}. Finally, this area is assigned to \texttt{A}. No additional memory is used, and \textbf{evaluations using \texttt{TEMPORARY} are faster}.

\item Avoid memory leaks when dealing with handles. This is easy, if you use the NASE system variable \texttt{!MH} as father for all handles you create. By freeing \texttt{!MH} (for master handle), you can also free the memory for all his children.

\end{itemize}



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{How long does it really take?}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

Here you can find results of some simple benchmark test. Different implementations of specific problems are compared, to find the most efficient way. Typically, the critical code was computed up to 10.000.000 times, to determine reliable estimations for time consumption. The order of this list is more or less the same as in the two previous chapters.

\begin{itemize}

\item Build-in functions are faster than loops. As an example the \texttt{TOTAL} function is compared to a \texttt{FOR}-loop to determin the sum of all elements of a vector. This comparison is done for different vector sizes:

\begin{enumerate}
\item \begin{verbatim} sum=0.
for i=0,n_elements(A)-1 do sum=sum+A[i]  \end{verbatim}
\item \begin{verbatim} sum=TOTAL(A)  \end{verbatim}
\end{enumerate}

Independent of \texttt{A}'s size, the \texttt{TOTAL} function is much faster than the loop. With small arrays of about five elements the difference is about a factor of 2.5. With larger arrays \texttt{TOTAL} is 55 times faster.

\item Invariant expressions in loops take a specific additional time that depends onto the expression itself and the loop count.

\item Needles type conversion takes a little amount of computational time, that can be avoided easily. Take a look at the two code fragments

\begin{enumerate}
\item \begin{verbatim} a=5.61 \end{verbatim}
\begin{verbatim} b=2.03 \end{verbatim}
\begin{verbatim} a=b+5 \end{verbatim}
\item \begin{verbatim} a=5.61 \end{verbatim}
\begin{verbatim} b=2.03 \end{verbatim}
\begin{verbatim} a=b+5. \end{verbatim}
\end{enumerate}

In the first case, the constant 5 has to be converted to a float value before the right side is evaluated. In the second no type conversion takes place. The first code seqment takes about 1.1 times longer. For single values, this is not serious, but using similar expressions with arrays will yield to factors of 2 or even more. When adding arrays of 1024 values for example, declaring wrong types takes 1.6 times longer. Type conversion times are independent of the types to be converted.

\item The first index of an array is processed fastest, at least in most cases. It depends on the operation that is performed to the array and to the 'direction'. Several cases have to be tested on two classes of array. First normal data arrays of the type \texttt{(time, parameter1, parameter2, parameter3)} should be considered in read and write operations of complete dimensions or only parts. Let's consider a typical data array \texttt{A} with time series of 2700 bin and three parameters (parameter1 has 16 values, the second 43 and the third 4). \texttt{A} can be arranged in four different ways:

\begin{enumerate}
\item \begin{verbatim} A=fltarr{2700,16,43,4} \end{verbatim}
\item \begin{verbatim} A=fltarr{16,2700,43,4} \end{verbatim}
\item \begin{verbatim} A=fltarr{16,43,2700,4} \end{verbatim}
\item \begin{verbatim} A=fltarr{16,43,4,2700} \end{verbatim}
\end{enumerate}

Copying vectors \texttt{B=fltarr(2700)} out \texttt{A}, i.e. to copy one whole dimension of 2700 time bins, takes the times described in table 1.

\begin{table}
\centering
\begin{tabular}{|c|c|c|} \hline
Dimension of Time & Reading Vector & Writing Vector\\ \hline \hline
1 & 6 s  & 57 s \\ \hline
2 & 44 s & 66 s \\ \hline
3 & 53 s & 65 s \\ \hline
4 & 85 s & 77 s \\ \hline
\end{tabular}
\caption{Time consumption of array operations copying one whole vector.}
\end{table}

There is a dramatic increase in time consumption. Using the first dimension for the time gives an advantage of 700\%. Writing \texttt{B} to \texttt{A} reveals similar time consumption for each dimension. There is only a slide tendency in favour of the first dimension.

Most often not the whole time series is needed but a small part of it. The same operations of reading and writing then have to be implemented with a sliding window, that cuts parts out of the time dimension. A repetition of the copying (read out of and write into array \texttt{A}) benchmark with a typical 128 bin sliding window provides time properties resumed in table 2.

\begin{table}
\centering
\begin{tabular}{|c|c|c|} \hline
Dimension of Time & Reading Vector & Writing Vector\\ \hline \hline
1 & 13 s & 63 s \\ \hline
2 & 47 s & 65 s \\ \hline
3 & 84 s & 71 s \\ \hline
4 & -- s & -- s \\ \hline
\end{tabular}
\caption{Time consumption of array operations copying parts of a vector with sliding window technique.}
\end{table}

Again the speed can be increased with reading processes. In every writing operation there is the same tendency, but no dramatic save of time. As a rule it is allways usefull to put the successional data into the very first dimension.

What about image styled arrays of the type \texttt{(x,y,parameter1,parameter2)} when the first two dimensions both are large. You should try to perform calculation rather on the rows than on the columns, because in memory, elements of row are physically neighboured. When this is impossible and every element of the image has to be computed with two loops, the order of the iterations is important.

\begin{enumerate}
\item \begin{verbatim} for x=0,Y-1 for y=0,X-1 do b=A(x,y)  \end{verbatim}
\item \begin{verbatim} for y=0,Y-1 for x=0,X-1 do b=A(x,y)  \end{verbatim}
\end{enumerate}

With small array, that fit into the physical working memory, there is no measurable difference. Evaluating very large arrays the the first implementation's performance drops, when the computer swaps. When the \texttt{x} loop is the inner one, then IDL can load for every \texttt{y} one row into the memory and perform the \texttt{x} loop. Alltogether Y continous rows have to be loaded into memory. In the other case (1.), IDL has to load columns, that are not safed continously to the disk. Do to the IDL help file, X*Y rows are loaded for this double loop, leading to a performance decrease of up to 50 times slower. A Test with an 160 \texttt{MB} array on a 128 \texttt{MB} computer showed only 1.3 times slower behaviour.

\item The \texttt{NOZERO} keyword speeds the declaration of an array, that needn't be initialized with zeros by a factor 15.

\item To change the values of an array or parts of it \texttt{REPLICATE\_INPLACE} is the fastest way. Let's consider the arrays \texttt{A} and \texttt{B}:

\begin{verbatim}
A=fltarr(2700,16,43)
B=fltarr(16,2700,43)
\end{verbatim}

To replace all values of one dimension by a constant, you can use the following two methods:

\begin{enumerate}
\item \begin{verbatim} A(*,1,1)=9.99 \end{verbatim}
\begin{verbatim} B(1,*,1)=9.99 \end{verbatim} 
\item \begin{verbatim} REPLICATE_INPLACE,A,9.99,1,[1,1,1] \end{verbatim}
\begin{verbatim} REPLICATE_INPLACE,B,9.99,2,[1,1,1] \end{verbatim}
\end{enumerate}

In both cases the \texttt{REPLICATE\_INPLACE} procedure is the best choice, with the first dimension it is 8.5 times faster, with the second 2 times. Note that \texttt{REPLICATE\_INPLACE} works with whole arrays and subarrays, too.

\item To expand an array by an integer factor \texttt{REBIN} and \texttt{CONGRID} can be used. \texttt{REBIN} is four times faster, than \texttt{CONGRID} with the keyword \texttt{CUBIC} that leads to 'nearly the same' result.

\item A clever expression order can save time. Take the example:
\begin{enumerate}
\item \begin{verbatim} B=A*16./MAX(A) \end{verbatim}
\item \begin{verbatim} B=16./MAX(A)*A \end{verbatim}
\item \begin{verbatim} for i=0,I do B(i)=A(i)*16./MAX(A) \end{verbatim}
\end{enumerate}

In the first case \texttt{A} is multiplied by 16 (each element of \texttt{A}!!!) and then devides by \texttt{MAX(A)}, i.e. two array operations. This is ponderous, because the right side of the expression can be reduced to one scalar and one array operation. As you can see in the second way of implementation, first 16 and \texttt{MAX(A)} are multiplicated and then this result is combined with \texttt{A}. The improvement is about 2.8 times.
As a deterrent example in the third case the same computation is implemented using a loop which drops the performance by a factor of 1515.

\item Loops and \texttt{if} statements should be avoided whereever possible. Replace them with optimal array operations! Here an example: Add \texttt{B}'s elements to \texttt{A} if they are positive. First try this:
\begin{verbatim}
for i=0,I do if C(i) gt 0 then A(i)=A(i)+C(i)
\end{verbatim}
It takes 69 s for some million repetitions. Using a byte mask like this
\begin{verbatim}
A=A+C(C gt 0)
\end{verbatim}
takes only 3 s. In this special case the next expression is even faster:
\begin{verbatim}
A=A+(C > 0)
\end{verbatim}
Using the maximum operator takes 2.5 s. That means 28 times faster than the loop implementation.


\item \texttt{TEMPORARY} not only safes memory, but the expression
\begin{verbatim}
A=TEMPORARY(A)+1
\end{verbatim}
is computed 1.5 times faster than the corresponding and memory wasting
\begin{verbatim}
A=A+1
\end{verbatim}




\end{itemize}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\subsection{Take Care! Traps and Bugs in IDL}
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%




\begin{itemize}

\item Respect the tag-by-value calling trap.

\item Take care of the typ-conversion order.

\item The \texttt{TEMPORARY} function does not work with subarrays. Consider this:

\begin{verbatim}
The TEMPORARY function can often be used to
conserve memory. However it's not immediately obvious (at least it
wasn't to me until recently) how to use TEMPORARY when extracting an
array subset.

For example, TEMPORARY saves no memory in the following example:

a = dist(256)
b = temporary(a[0:63, 0:63])
help, a, b
A               FLOAT     = Array[256, 256]
B               FLOAT     = Array[64, 64]

The argument a[0:63, 0:63] is passed to TEMPORARY by value, and
therefore cannot be modified. However the following method *does* save
memory:

a = dist(256)
b = (temporary(a))[0:63, 0:63]
help, a, b
A               UNDEFINED = <Undefined>
B               FLOAT     = Array[64, 64]

Cheers,
Liam.
http://cimss.ssec.wisc.edu/~gumley
\end{verbatim}


\end{itemize}




%\bibliography{standards}
%\bibliographystyle{plainnat} 
\end{document}
